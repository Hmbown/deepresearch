# Models
ORCHESTRATOR_MODEL=openai:gpt-5.2
SUBAGENT_MODEL=openai:gpt-5.2

# Required provider key for default models
OPENAI_API_KEY=

# OpenAI transport options (default runtime uses Responses API)
OPENAI_USE_RESPONSES_API=true
OPENAI_OUTPUT_VERSION=responses/v1
OPENAI_USE_PREVIOUS_RESPONSE_ID=false

# Search provider configuration (supported: tavily, exa, none)
SEARCH_PROVIDER=tavily
# Search provider key (required when SEARCH_PROVIDER=tavily â€” default)
TAVILY_API_KEY=
# Search provider key (required when SEARCH_PROVIDER=exa)
EXA_API_KEY=

# Optional low-noise runtime event logs
ENABLE_RUNTIME_EVENT_LOGS=false

# Runtime knobs
MAX_STRUCTURED_OUTPUT_RETRIES=
MAX_REACT_TOOL_CALLS=
MAX_CONCURRENT_RESEARCH_UNITS=
MAX_RESEARCHER_ITERATIONS=

# Online evaluations (LLM-as-judge scoring on LangSmith traces)
ENABLE_ONLINE_EVALS=false
EVAL_MODEL=openai:gpt-4.1-mini

# LangSmith tracing
# Keep tracing off by default. Enable when you want LangSmith traces.
LANGCHAIN_TRACING_V2=false
# LANGSMITH_TRACING=true
LANGCHAIN_API_KEY=
# LANGSMITH_API_KEY=
LANGCHAIN_PROJECT=deepresearch-local
# LANGSMITH_PROJECT=deepresearch-local
# Optional custom endpoint
# LANGCHAIN_ENDPOINT=https://api.smith.langchain.com
